{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiez automatiquement des biens de consommation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pt5cYPH-cHr"
   },
   "source": [
    "## 1.1 Problématique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bawzfKfP-cHs"
   },
   "source": [
    "L’entreprise \"Place de marché”, <br />\n",
    "souhaite lancer une marketplace e-commerce.\n",
    "\n",
    "Sur la place de marché, des vendeurs <br />\n",
    "proposent des articles à des acheteurs <br />\n",
    "en postant une **photo** et une **description**.\n",
    "\n",
    "Pour l'instant, l'attribution de la catégorie<br /> \n",
    "d'un article est effectuée manuellement par <br />\n",
    "les vendeurs et est donc peu fiable. <br />\n",
    "De plus, le volume des articles est <br />\n",
    "pour l’instant très petit.\n",
    "\n",
    "Pour rendre l’expérience utilisateur <br />\n",
    "des vendeurs (faciliter la mise en ligne <br />\n",
    "de nouveaux articles) et des acheteurs (faciliter <br />\n",
    "la recherche de produits) la plus fluide <br />\n",
    "possible et dans l'optique d'un passage <br />\n",
    "à l'échelle, il devient nécessaire d'automatiser <br />\n",
    "cette tâche.\n",
    "\n",
    "Il nous est demandé d'étudier la faisabilité <br />\n",
    "d'un moteur de classification des articles <br />\n",
    "en différentes catégories, avec un niveau <br />\n",
    "de précision suffisant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf8GHFjw-cHs"
   },
   "source": [
    "## 1.2 Objectifs dans ce projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVzqFMTT-cHs"
   },
   "source": [
    "Réaliser une première **étude de faisabilité d'un moteur <br />\n",
    "de classification d'articles** basé sur une <u>image</u> et une <br />\n",
    "<u>description</u> pour l'automatisation de l'attribution <br />\n",
    "de la *catégorie de l'article*.\n",
    "\n",
    "**Analyser le jeu de données** en réalisant un <u>prétraitement <br />\n",
    "des images et des descriptions</u> des produits, une <u>réduction <br />\n",
    "de dimension</u>, puis un <u>clustering</u>.\n",
    "\n",
    "Les résultats du clustering seront présentés sous la forme <br />\n",
    "d’une **représentation en deux dimensions**, qui illustrera <br />\n",
    "le fait que <u>les caractéristiques extraites permettent <br />\n",
    "de regrouper des produits de même catégorie</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEPdWd4Xf4zU"
   },
   "source": [
    "# 2. Import des librairies et réglage de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "# !pip install texthero\n",
    "import texthero as hero\n",
    "\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Pandas settings for\n",
    "# be able to display more rows and more columns.\n",
    "pd.set_option(\"max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Déclaration des fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai décomposé en fonctions toutes les actions <br />\n",
    "clés réalisés dans ce projet afin :<br />\n",
    " - d'améliorer la lecture du code et de ma démarche\n",
    " - de donner la possibilité à quiconque de facilement <br />\n",
    "   réutiliser mon code pour ses propres projets.\n",
    "   \n",
    "<u>L'ensemble des fonctions que j'ai écrit</u> et utilisé <br />\n",
    "dans ce projet, pour les parties concernant <br />\n",
    "le traitement du texte, des images ou <br />\n",
    "du texte + images <u>sont listés ci-dessous</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_product_category_tree(txtATraiter):\n",
    "    '''\n",
    "    Returns the first element of product_category_tree\n",
    "    '''\n",
    "    return txtATraiter.replace('[\"','')\\\n",
    "                      .replace('\"]','')\\\n",
    "                      .replace(' >> ','>>')\\\n",
    "                      .split('>>')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_filter_english_words(txtToLemmatize,\n",
    "                               toSentence=True,\n",
    "                               tagFilter=None):\n",
    "    '''\n",
    "    This function lemmatizes the sentence given as argument.\n",
    "    It returns the choice:\n",
    "     - a lemmatized sentence\n",
    "     - a list containing each term of the lematized sentence.\n",
    "    In addition, it is possible to communicate a list containing \n",
    "    the nature or function of the words to be returned,\n",
    "    the others will be ignored and deleted.\n",
    "    The list of terms available for <tagFilter> are:\n",
    "     - r': Adverb\n",
    "     - n': Name\n",
    "     - v': Verb\n",
    "     '''\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk import pos_tag, word_tokenize\n",
    "    sentenceToReturn = []\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    # Tokenize et tag each word of the sentence\n",
    "    for word, tag in pos_tag(word_tokenize(txtToLemmatize)):\n",
    "        # first letter in low case for the lemmatize fonction parameter\n",
    "        wntag = tag[0].lower()\n",
    "    \n",
    "        if tagFilter:\n",
    "            wntag = wntag if wntag in tagFilter else None\n",
    "        else:\n",
    "            wntag = wntag if wntag in ['r', 'n', 'v'] else None\n",
    "            \n",
    "        if wntag:\n",
    "            lemma = wnl.lemmatize(word.lower(), wntag) \n",
    "        else:\n",
    "            if tagFilter:\n",
    "                continue\n",
    "            else:\n",
    "                lemma = word.lower()\n",
    "                \n",
    "        sentenceToReturn.append(lemma)\n",
    "    \n",
    "    if toSentence:\n",
    "        return ' '.join(word for word in sentenceToReturn)\n",
    "    else:\n",
    "        return sentenceToReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_only_integers(tup):\n",
    "    '''\n",
    "    This function returns <True> if the tupple \n",
    "    input communiqué contains only <int>.\n",
    "    Returns <False> in all other cases.\n",
    "    '''\n",
    "    for item in tup:\n",
    "        if not isinstance(item, int):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuppleOfTwoInt(var=False, varName=''):\n",
    "    '''\n",
    "    Indicates whether the format of the argument <var> \n",
    "    is well communicated in the right format.\n",
    "    The expected formats are: int or tupple of 2 int.\n",
    "    If var is an int then the function returns \n",
    "    a tupple in the format (var,var) \n",
    "    If var is a tupple of 2 int, the function returns \n",
    "    the tuple <var> as is.\n",
    "    Returns False without an error message if <var> is equal to False.\n",
    "    Returns False with an error message indicating \n",
    "    that the format is not valid in all other cases.\n",
    "    '''\n",
    "    if varName:\n",
    "        varName = str.strip(varName)+' '\n",
    "    if isinstance(var, bool):\n",
    "        if var:\n",
    "            print(f'TuppleOfTwoInt : The format of the {varName}argument is incorrect')\n",
    "        return False\n",
    "    elif isinstance(var, int):\n",
    "        return (var,var)    \n",
    "    elif isinstance(var, tuple):\n",
    "        if contains_only_integers(var):\n",
    "            if len(var) == 2:\n",
    "                return var    \n",
    "    print(f'TuppleOfTwoInt : The format of the {varName}argument is incorrect')\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessingImage(img, resize=False, gray=False, gaus=False, gausKernel=5, equ=False):\n",
    "    '''\n",
    "    Returns an image <img>, previously processed.\n",
    "    Processing may include:\n",
    "     - Image resizing\n",
    "     - Switching to grey level\n",
    "     - Gaussian Blur\n",
    "     - Equalizer\n",
    "    The function accepts as input either \n",
    "    an image, or the path of an image.\n",
    "    '''\n",
    "    \n",
    "    if isinstance(img, str):\n",
    "        # We consider that it is not an image but the path of the image\n",
    "        img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    resize = tuppleOfTwoInt(var=resize, varName='resize')\n",
    "    if resize:\n",
    "        img = cv2.resize(img, resize)\n",
    "    if gray:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    if gaus and tuppleOfTwoInt(var=gausKernel, varName='gausKernel'):\n",
    "        gausKernel = tuppleOfTwoInt(var=gausKernel, varName='gausKernel')\n",
    "        img = cv2.GaussianBlur(img, gausKernel, cv2.BORDER_DEFAULT)\n",
    "    if equ:\n",
    "        img = cv2.equalizeHist(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptorExtraction(img):\n",
    "    '''\n",
    "    Returns the SIFT descriptors \n",
    "    of the image or of the image path <img> \n",
    "    communicated as an argument.\n",
    "    '''\n",
    "    \n",
    "    if isinstance(img, str):\n",
    "        # We consider that it is not an image but the path of the image\n",
    "        img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    img = preProcessingImage(img, gray=True, gaus=True, equ=True)\n",
    "    sift = cv2.xfeatures2d.SIFT_create() # Création de l'objet SIFT\n",
    "    _, des = sift.detectAndCompute(img,None)\n",
    "    return des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupAllDescriptors(dictData):\n",
    "    '''\n",
    "    Calculates a matrix containing all the descriptors\n",
    "    calculated from a series of images.\n",
    "    \n",
    "    The images are read from the dictionary \n",
    "    communicated as argument with the key \"path\" that\n",
    "    contains a list (or equivalent) of accesses to each image.\n",
    "    \n",
    "    The function creates the key \"totalDes\" containing \n",
    "    the descriptor matrix and then returns the dictionary.\n",
    "    '''\n",
    "    totalDes = []\n",
    "    for img in dictData['path']:\n",
    "        des = descriptorExtraction(img)\n",
    "        totalDes.extend(des)\n",
    "    dictData['totalDes'] = np.array(totalDes, dtype=np.int)\n",
    "    return dictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createKmeansOfBagOfVirtualWords(dictData):\n",
    "    '''\n",
    "    Returns a trained MiniBatchKMeans including \n",
    "    Labels represent virtual words \n",
    "    calculated from the matrix of descriptors \n",
    "    contained in the \"totalDes\" key of the dictionary \n",
    "    communicated as an argument.\n",
    "    \n",
    "    The MiniBatchKMeans is contained in \n",
    "    the \"kmeans\" key of the dictionary.\n",
    "    \n",
    "    The number of clusters is determined by \n",
    "    the square root of the number of descriptors.\n",
    "    \n",
    "    the batch size argument is equal to 3 times \n",
    "    the number of images in total.\n",
    "    \n",
    "    Returns the dictData dictionary.\n",
    "    '''\n",
    "    \n",
    "    # definition of clustering parameters\n",
    "    nClusters = int(round(np.sqrt(dictData['totalDes'].shape[0]),0))\n",
    "    batchSize = dictData['path'].shape[0]*3\n",
    "\n",
    "    print('nClusters =',nClusters)\n",
    "    print('batchSize =',batchSize)\n",
    "\n",
    "    dictData['kmeans'] = MiniBatchKMeans(n_clusters=nClusters,\n",
    "                                         batch_size=batchSize).fit(dictData['totalDes'])\n",
    "    return dictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrixOfImages(dictData, size=224):\n",
    "    '''\n",
    "    Creates a 4-dimensional matrix from \n",
    "    a list of images or path to the images.\n",
    "    The 4 dimensions of the matrix are \n",
    "    distributed as below:\n",
    "     - 1st dimension: Number of images\n",
    "     - 2nd and 3rd dimension: Length and width of the image\n",
    "     - 4th dimension: Depth of the image. \n",
    "        - Is equal to 3 if image is in color.\n",
    "        - Is equal to 1 if image is grayscale.\n",
    "    The function expects a dictionary as argument.\n",
    "    The communicated images must be present \n",
    "    in the \"path\" key of the dictionary.\n",
    "    This function is intended to return a matrix \n",
    "    that will be used as input for a VGG16 neural network.\n",
    "    This neural network expects as input fixed \n",
    "    size images, by default square images of 224px side.\n",
    "    This value can be modified with the argument <size>.\n",
    "    The array is created and added to the \n",
    "    dictionary in the key \"arrayImg\".\n",
    "    The function returns the dictionary.\n",
    "    '''\n",
    "    listImages = []\n",
    "    \n",
    "    for img in dictData['path']:\n",
    "        img = preProcessingImage(img, resize=size)\n",
    "        img = preprocess_input(img)\n",
    "        listImages.append(img)\n",
    "    print(f'Dimensions of the image matrix: {np.array(listImages).shape}')\n",
    "    dictData['arrayImg'] = np.array(listImages)\n",
    "    return dictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHistograms(dictData):\n",
    "    '''\n",
    "    This function calculates the normalized histograms \n",
    "    of the images (or path of the images) contained \n",
    "    in the \"path\" key of the dictionary communicated as argument.\n",
    "    The images are listed in a List or equivalent.\n",
    "    The normalization is performed from the 1st dimension \n",
    "    of the matrix containing the set of descriptors.\n",
    "    This matrix is stored in the \"totalDes\" key of the dictionary.\n",
    "    A numpy array containing the histograms is created \n",
    "    and added to the dictionary to the \"histograms\" key.\n",
    "    The function returns the dictionary.\n",
    "    '''\n",
    "    list_histo = []\n",
    "    for count, image in enumerate(dictData['path']):\n",
    "        print(f'image processing number {count+1}/{dictData[\"path\"].shape[0]}')\n",
    "        # Vector of 0 equal in size to the number of unique labels in kmeans\n",
    "        histo = np.zeros(len(set(dictData['kmeans'].labels_)))\n",
    "        # Number of key points, for Histogram Normalisation\n",
    "        nkp = dictData['totalDes'].shape[0] \n",
    "        \n",
    "        for d in descriptorExtraction(image):\n",
    "            idx = dictData['kmeans'].predict([d])\n",
    "            histo[idx] += 1/nkp\n",
    "        list_histo.append(histo)\n",
    "    dictData['histograms'] = np.array(list_histo)\n",
    "    print(f'Dimensions of the histogram matrix: {dictData[\"histograms\"].shape}')\n",
    "    return dictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reductionTwoDimensionPCAandTSNE(dictData, col='histograms', pcaComponents=0.99):\n",
    "    '''\n",
    "    This function applies a PCA transformation \n",
    "    followed by a T-SNE transformation to a data set.\n",
    "    The choice of PCA preprocessing is chosen to reduce \n",
    "    T-SNE computation time.\n",
    "    \n",
    "    The function expects a dictionary as argument.\n",
    "    The data to be processed can be accessed with \n",
    "    the key <col> of the dictionary.\n",
    "    The key <col> is given as argument.\n",
    "    \n",
    "    By default, PCA keeps 99% of the variance.\n",
    "    It is possible to determine the parameter \n",
    "    <n_components> of PCA with the argument <pcaComponents>.\n",
    "    \n",
    "    T-SNE is set to return the data set from \n",
    "    the PCA transformation, with only 2 output dimensions.\n",
    "    \n",
    "    The result is added to the dictionary with the key \"tsne\".\n",
    "    The function returns the dictionary.\n",
    "    '''\n",
    "    \n",
    "    from scipy.sparse import issparse\n",
    "    \n",
    "    print(f'Treatment of the column {col}')\n",
    "    print(f'Dimension of the original data set: {dictData[col].shape}')\n",
    "    print('Start of PCA processing:')\n",
    "    \n",
    "    \n",
    "    if pcaComponents <= 1:\n",
    "        print(f'Variance preserved: {pcaComponents*100}%')\n",
    "    else:\n",
    "        print(f'Number of components conserved: {pcaComponents}')\n",
    "        \n",
    "    pca = PCA(n_components=pcaComponents)\n",
    "    \n",
    "    if issparse(dictData[col]):\n",
    "        X_pca = pca.fit_transform(dictData[col].toarray())\n",
    "    else:\n",
    "        X_pca = pca.fit_transform(dictData[col])\n",
    "    \n",
    "    print(f'Data set size after PCA processing: {X_pca.shape}')\n",
    "    print('End of PCA processing.')\n",
    "    print(f'Start T-SNE processing:')\n",
    "    \n",
    "    tsne = TSNE(n_components=2)\n",
    "    X_tsne = tsne.fit_transform(X_pca)\n",
    "    \n",
    "    print(f'Size of the dataset after T-SNE processing: {X_tsne.shape}')\n",
    "    print(f'End of T-SNE processing.')\n",
    "    \n",
    "    dictData['tsne'] = X_tsne\n",
    "    \n",
    "    return dictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayTheFourImagesAndTheirHistograms(dictData, idx):\n",
    "    '''\n",
    "    Displays the same image 4 times in \n",
    "    succession with its associated histogram.\n",
    "    The displayed image will be read from the index <idx>. \n",
    "    of the \"path\" key of the dictionary \n",
    "    communicated as an argument.\n",
    "    Each image is displayed with a different \n",
    "    treatment in this order:\n",
    "     1) No processing\n",
    "     2) GrayScale\n",
    "     3) GrayScale + Gaussian Blur\n",
    "     4) GrayScale + Gaussian Blur + Equalization\n",
    "     To display an image, the function calls \n",
    "     the <drawImageAndHistogram> function \n",
    "     with the appropriate parameters.\n",
    "    '''\n",
    "    drawImageAndHistogram(dictData,idx=idx,preprocessing=[])\n",
    "    drawImageAndHistogram(dictData,idx=idx,preprocessing=['gray'])\n",
    "    drawImageAndHistogram(dictData,idx=idx,preprocessing=['gray','gaus'])\n",
    "    drawImageAndHistogram(dictData,idx=idx,preprocessing=['gray','gaus','equ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawImageAndHistogram(dictData,idx=0,preprocessing=[]):\n",
    "    '''\n",
    "    Displays an image and its associated histogram.\n",
    "    The displayed image will be read from the index <idx> \n",
    "    of the \"path\" key of the dictionary given as argument.\n",
    "    Before displaying an image, a preprocessing list \n",
    "    can be applied to it.\n",
    "    The list of preprocessing to be performed must \n",
    "    be given in the argument <preprocessing>.\n",
    "    The list of possible arguments are:\n",
    "     - \"gray\" --> \"Gray Scale\"\n",
    "     - \"gaus\" --> \"Gaussian Blur\"\n",
    "     - \"equ\" --> \"Equalize Histogram\"\n",
    "    The title of the created image indicates \n",
    "    the list of preprocessing performed or \n",
    "    indicates \"None\" if no preprocessing has been chosen.\n",
    "    '''\n",
    "    gray=gaus=equ=False\n",
    "    \n",
    "    if 'gray' in preprocessing:\n",
    "        gray=True\n",
    "    if 'gaus'in preprocessing:\n",
    "        gaus=True\n",
    "    if 'equ' in preprocessing:\n",
    "        equ=True\n",
    "\n",
    "    # Matching the terms of the transformation to display the graph title\n",
    "    dictTransformations={'gray':'Gray Scale',\n",
    "                         'gaus':'Gaussian Blur',\n",
    "                         'equ': 'Equalize Histogram'}\n",
    "    # We add an 's' to 'transformation' in the title \n",
    "    # of the graph if we apply several transformations\n",
    "    if len(preprocessing) > 1:\n",
    "        s='s'\n",
    "    else:\n",
    "        s=''\n",
    "    # Formatting of applied transformations\n",
    "    if preprocessing == []:\n",
    "        listTransformations = 'None'\n",
    "    else:\n",
    "        listTransformations = ' + '.join({ preprocessing: dictTransformations[preprocessing]\\\n",
    "                                          for preprocessing in preprocessing }.values())\n",
    "        \n",
    "    \n",
    "    img = preProcessingImage(dictData['path'][idx],\n",
    "                             gray=gray,\n",
    "                             gaus=gaus,\n",
    "                             gausKernel=5,\n",
    "                             equ=equ)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Creation of the graph title\n",
    "    graphTitle = ''.join([dictData['path'][idx].split('/')[-1],\n",
    "                          '\\nTransformation'+s+': ',listTransformations])\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    fig.suptitle(graphTitle, fontsize=14)\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.title.set_text('Analyzed image')\n",
    "    ax1.imshow(img, cmap='gray')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.title.set_text('Histogram')\n",
    "    ax2.hist(img.ravel(),256,[0,256])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayTSNESortedByColor(dictData,hue='category',figsize=(20,10)):\n",
    "    '''\n",
    "    Displays a scatterplot of a 2-dimensional matrix \n",
    "    contained in the key \"tsne\" of the dictionary \n",
    "    communicated as argument.\n",
    "    The idea is to display the result of a T-SNE \n",
    "    dimension reduction in 2 dimensions.\n",
    "    The color of the points is a function of the \n",
    "    argument <hue> communicated in argument and \n",
    "    refers to a key of the dictionary.\n",
    "    '''\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title('Product classified by colors according to their '+hue,\n",
    "              fontsize=24)\n",
    "    cmap = sns.color_palette(\"tab10\",\n",
    "                             n_colors=dictData[hue].nunique())\n",
    "    sns.scatterplot(x=dictData['tsne'][:,0],\n",
    "                    y=dictData['tsne'][:,1],\n",
    "                    hue=dictData[hue],\n",
    "                    palette=cmap)\n",
    "    sns.color_palette(\"rocket_r\",\n",
    "                      as_cmap=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createKMeansLabelsFromTSNE(dictData, n_clusters=7):\n",
    "    '''\n",
    "    This function calculates the Labels of a KMeans.\n",
    "    The function expects a dictionary as argument.\n",
    "    The calculated labels are added to the \n",
    "    dictionary with the key \"labels\".\n",
    "    The number of clusters of the KMeans is \n",
    "    communicated as an entry in the argument \"n_clusters\".\n",
    "    The data to be clustered are present \n",
    "    in the dictionary with the key \"tsne\".\n",
    "    The idea of this function is to cluster \n",
    "    the data in 2 dimensions resulting from \n",
    "    a dimension reduction with T-SNE.\n",
    "    Returns the dictionary.\n",
    "    '''\n",
    "    dictData['labels'] = pd.Series(KMeans(n_clusters=n_clusters)\\\n",
    "                                   .fit(dictData['tsne'])\\\n",
    "                                   .labels_,\n",
    "                                   name='labels')\n",
    "    return dictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewARIScore(dictData):\n",
    "    '''\n",
    "    Calculates and displays the ARI score of the data \n",
    "    coming from the \"category\" and \"labels\" keys of \n",
    "    the dictionary communicated as argument.\n",
    "    '''\n",
    "    print('ARI score between clustering according\\nto categories and KMeans labels:',\n",
    "          adjusted_rand_score(dictData['category'],\n",
    "                              dictData['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showConfusionMatrix(dictData,\n",
    "                        y_true='category',\n",
    "                        y_pred='labels',\n",
    "                        xlabel='Clusters',\n",
    "                        ylabel='Product Categories'):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    # We guard against cases where y_true or y_pred are not numbers.\n",
    "    le_true = LabelEncoder()\n",
    "    le_pred = LabelEncoder()\n",
    "    y_true= le_true.fit_transform(dictData[y_true])\n",
    "    y_pred = le_pred.fit_transform(dictData[y_pred])\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.heatmap(cm,\n",
    "                fmt=\"d\",\n",
    "                annot=True,\n",
    "                linewidths=.5,\n",
    "                xticklabels=le_pred.classes_,\n",
    "                yticklabels=le_true.classes_)\n",
    "    plt.xlabel(xlabel, fontsize=16)\n",
    "    plt.ylabel(ylabel, fontsize=16)\n",
    "    plt.title('Confusion Matrix', fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineTwoMatricesInOne(dictData,\n",
    "                            finalKey='vectors',\n",
    "                            key1='tfidf',\n",
    "                            key2='histograms'):\n",
    "    '''\n",
    "    This function joins 2 matrices into 1.\n",
    "    The matrices are joined on their horizontal axis.\n",
    "    Both matrices must have the same number of lines.\n",
    "    The generated matrix has the same number of lines \n",
    "    in input as in output.\n",
    "    The generated matrix has a number of columns equal \n",
    "    to the number of columns of the 1st matrix + the \n",
    "    number of columns of the 2nd matrix.\n",
    "    The function expects a dictionary as argument.\n",
    "    The matrices are present at the indexes of the \n",
    "    dictionary designated by the arguments <key1> and <key2>.\n",
    "    The new generated matrix is stored in the \n",
    "    dictionary at the key <finalKey> given as argument.\n",
    "    The function returns the dictionary.\n",
    "    '''\n",
    "    vectors = []\n",
    "    \n",
    "    print('Dimensions of two matrices:')\n",
    "    print(f'   Matrix n°1 -- Name: {key1} -- Shape: {dictData[key1].shape}')\n",
    "    print(f'   Matrix n°2 -- Name: {key2} -- Shape: {dictData[key2].shape}')\n",
    "    \n",
    "    for idx,vect in enumerate(dictData[key1]):\n",
    "        vectors.append(np.concatenate((vect.toarray()[0],\n",
    "                                       dictData[key2][idx])))\n",
    "    dictData[finalKey] = np.array(vectors)\n",
    "    print(f'Final matrix -- Name: {finalKey} -- Shape: {dictData[finalKey].shape}')\n",
    "    return dictData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Flipkart/flipkart_com-ecommerce_sample_1050.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Analyse du DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Types des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Dimensions du DataFrame data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Cardinalité de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Classification des produits grâce <br />à leurs données textuelles descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Préparation, Analyse des Features Textuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie nous allons **classer** <br />\n",
    "et **regrouper** nos produits en autant de <br />\n",
    "groupes qu'il existe de <u>catégories</u>. <br />\n",
    "Nous réaliserons cela à travers <br />\n",
    "notre **moteur de classification** à partir <br />\n",
    "des <u>textes qui servent à les décrire</u>.\n",
    "\n",
    "<u>L'objectif et d'obtenir du moteur <br />\n",
    "de classification, le regroupement <br />\n",
    "le plus proche par rapport au <br />\n",
    "classement de référence initial</u>.\n",
    "\n",
    "<u>Nous émettons l'hypothèse</u> qu'un **produit <br />\n",
    "peut-être attribué à une catégorie à <br />\n",
    "partir du vocubulaire utilisé dans sa description**.\n",
    "\n",
    "<u>2 features permettent de décrire un produit</u> :\n",
    " - Le titre de l'annonce: \"**product_name**\"\n",
    " - La description de l'objet: \"**description**\"\n",
    "\n",
    "Nous allons mettre en place le moteur de classification.<br />\n",
    "Pour **optimiser ses performances**, nous allons devoir <br />\n",
    "**pré-traiter les textes**.\n",
    "\n",
    "L’objectif est, d’une part, de <u>débarrasser les textes</u> <br />\n",
    "de tous les <u>éléments inutiles</u> qui n’apportent pas <br />\n",
    "d’information permettant d’identifier le produit<br />\n",
    "et d’autre part de *normaliser* le texte afin qu’un <br />\n",
    "mot utilisé dans la description d’un produit ait <br />\n",
    "exactement la même orthographe dans les autres <br />\n",
    "descriptions des autres produits (gestion de la casse,<br /> \n",
    "de l’accord en genre et en nombre, verbes conjugués <br />\n",
    "convertis dans leur forme à l’infinitif, etc.)\n",
    "\n",
    "Alors seulement nous pourrons créer <br />\n",
    "un **bag of words** constitué des seuls éléments<br /> \n",
    "de vocabulaire ayant une importance pour <br />\n",
    "décrire nos produits.\n",
    "\n",
    "*Un bag of words nous sert à décrire un document.<br />\n",
    "Chaque mot représente une feature, une caractéristique.<br />\n",
    "L'ensemble de plusieurs caractéristiques permet de<br />\n",
    "décrire un produit et ainsi déterminer sa catégorie.*\n",
    "\n",
    "Notre moteur de classification attribuera à <br />\n",
    "chaque produit un **vecteur de caractéristiques**, <br />\n",
    "qui sera fonction des **termes descriptifs** inclus <br />\n",
    "dans sa description et **pondéré** avec l’ensemble <br />\n",
    "des termes existants pour décrire <br />\n",
    "l’ensemble des produits de notre jeu de données.\n",
    "\n",
    "Pour **améliorer les performances** et également <br />\n",
    "permettre de **visualiser la clusterisation des produits** <br />\n",
    "de notre moteur de classification, nous procèderons <br />\n",
    "à une <u>réduction en 2 dimensions</u> des vecteurs de caractéristiques.\n",
    "\n",
    "Via une **clusterisation**, notre moteur **regroupera** ensemble <br />\n",
    "les produits qu’il estimera **appartenir à la même catégorie**.\n",
    "\n",
    "Enfin, nous pourrons **évaluer** notre moteur de <br />\n",
    "classification en **comparant** le regroupement de <br />\n",
    "l’ensemble des produits réalisé par notre moteur de <br />\n",
    "classification avec la catégorie réelle de chaque produit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Sélection des features à traiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Seules 3 features nous interresse dans cette partie</u> :\n",
    " - '**product_name**' correspond au titre du produit\n",
    " - '**description**' comme son nom l'indique, à sa description\n",
    " - '**product_category_tree**' renseigne sur la catégorie du produit.<br />\n",
    "   Ce champ est précis et contient l'ensemble des catégories<br />\n",
    "   et sous catégories associées au produit et <u>n'est pas exploitable en l'état</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()[['product_name','description','product_category_tree']]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Fusion des colonnes 'product_name' et 'description'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je fusionne le titre et la description du produit<br />\n",
    "pour ne garder qu'un <u>unique champ</u> contenant<br />\n",
    "l'<u>ensemble des termes</u> décrivant l'objet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_desc'] = df['product_name']+' '+df['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Traitement de la main category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque produit est caractérisé par la <br />\n",
    "catégorie qui lui est associé.<br />\n",
    "Il existe plusieurs niveaux de catégorie.<br />\n",
    "Pour l'exercice nous n'allons <u>conserver <br />\n",
    "que la **catégorie principale**</u> de chaque produit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.1 Extraction de la main category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de la feature \"category\" qui contient <br />\n",
    "le nom de la catégorie principale de chaque produit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = df['product_category_tree']\\\n",
    "                   .apply(lambda row: first_product_category_tree(row))\n",
    "df.drop('product_category_tree',\n",
    "        axis=1,\n",
    "        inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3.2 Statistique sur la main category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.3.2.1 Nombre d'articles par catégorie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Les produits sont parfaitements répartis entre les catégories</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.3.2.2 Nombre de mots en moyenne par description  et par titre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Je crée 3 colonnes contenant<br />\n",
    "    le nombre de mots dans les features</u> :\n",
    " - \"**description**\"\n",
    " - \"**product_name**\"\n",
    " - \"**title_desc**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that a sentence with n words has n-1 spaces in it\n",
    "df['count_description'] = df['description']\\\n",
    "                            .apply(lambda row: row.count(' ') + 1)\n",
    "df['count_title'] = df['product_name']\\\n",
    "                            .apply(lambda row: row.count(' ') + 1)\n",
    "df['count_title_description'] = \\\n",
    "        df['title_desc'].apply(lambda row: row.count(' ') + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.groupby('category').mean()[['count_description',\n",
    "                                     'count_title',\n",
    "                                     'count_title_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "sns.lineplot(x=cat.index,\n",
    "             y=cat['count_description'],\n",
    "             linewidth=3,\n",
    "             marker='o',\n",
    "             markersize=20,\n",
    "             label='description')\n",
    "\n",
    "sns.lineplot(x=cat.index,\n",
    "             y=cat['count_title'],\n",
    "             linewidth=3,\n",
    "             marker='o',\n",
    "             markersize=20,\n",
    "             label='title')\n",
    "\n",
    "sns.lineplot(x=cat.index,\n",
    "             y=cat['count_title_description'],\n",
    "             linewidth=3,\n",
    "             marker='o',\n",
    "             markersize=20,\n",
    "             label='description + title')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Category',fontsize=16)\n",
    "plt.xticks(rotation=20,ha='right')\n",
    "plt.ylabel('Number of words',fontsize=16)\n",
    "plt.title('Number of words per category', fontsize=24)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de mots utilisés en moyenne<br />\n",
    "pour décrire un produit est <u>inégalement <br />\n",
    "réparti</u> entre les catégories, pouvant <br />\n",
    "aller pratiquement du <u>simple au double</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Traitement du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette étape est très importante pour l'**optimisation** <br />\n",
    "de notre moteur de classification.\n",
    "\n",
    "Nous allons **nettoyer** et **normaliser** nos descriptions <br />\n",
    "en effectuant un ensemble d'opérations détaillées ci-dessous.\n",
    "\n",
    "Pour cette étape, j'utilise la bilibliothèque **texthero**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Nettoyage et Normalisation du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilisation de text hero**:\n",
    "\n",
    "<u>La méthode clean effectue le traitement suivant</u> :\n",
    "1. texthero.preprocessing.**fillna()**\n",
    "2. texthero.preprocessing.**lowercase()**<br />\n",
    "&emsp;- *Passe la chaîne de caractère en minuscule*\n",
    "3. texthero.preprocessing.**remove_digits()**<br />\n",
    "&emsp;- *Remplace tous les digits par un seul espace*\n",
    "4. texthero.preprocessing.**remove_punctuation()**<br />\n",
    "&emsp;- *Remplace tous les signes de <br />\n",
    "&emsp;&ensp;ponctuation par un seul espace*\n",
    "5. texthero.preprocessing.**remove_diacritics()**<br />\n",
    "&emsp;- *Supprime tous les diacritiques et les accents*\n",
    "6. texthero.preprocessing.**remove_stopwords()**<br />\n",
    "&emsp;- *Supprime les stopwords issues <br />\n",
    "&emsp;&ensp;d'une liste de 179 stopwords de <br />\n",
    "&emsp;&ensp;la bibliothèque NLTK.*\n",
    "7. texthero.preprocessing.**remove_whitespace()**<br />\n",
    "&emsp;- *Supprime les espaces inutiles en début et <br />\n",
    "&emsp;&ensp;en fin de chaîne, les sauts de ligne, <br />\n",
    "&emsp;&ensp;les tabulations et toute forme d'espace*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>J'affiche un exemple de description, <br />\n",
    "**avant** et **après** traitement</u> :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Avant** Normalisation</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of words : {df.title_desc[0].count(\" \") + 1}\\n')\n",
    "print(df.title_desc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_desc_clean'] = df['title_desc'].pipe(hero.clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Après** Normalisation</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of words : {df[\"title_desc_clean\"][0].count(\" \") + 1}\\n')\n",
    "print(df['title_desc_clean'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Lemmatisation du texte et<br />Filtrage des Noms + Verbes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le processus de « **lemmatisation** » consiste<br />\n",
    "à représenter les mots (ou « lemmes ») <br />\n",
    "sous leur forme *canonique*.<br />\n",
    "Par exemple pour un verbe, ce sera son infinitif.<br />\n",
    "Pour un nom, son masculin singulier.<br />\n",
    "L'idée étant encore une fois de ne **conserver <br />\n",
    "que le sens des mots** utilisés dans le corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, dans notre objectif de ne <u>conserver que<br />\n",
    "des features permettant de décrire un objet</u>,<br />\n",
    "nous allons filtrer les résultats pour ne conserver <br />\n",
    "que les **Noms** et **Verbes** des descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_desc_lemma'] = \\\n",
    "    df['title_desc_clean']\\\n",
    "        .apply(lambda row: \\\n",
    "               lemma_filter_english_words(row,\n",
    "                                          tagFilter=['n',\n",
    "                                                     'v']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Avant** lemmatisation</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of words : {df.loc[0,\"title_desc_clean\"].count(\" \") + 1}\\n')\n",
    "df.loc[0,'title_desc_clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Après** lemmatisation</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of words : {df.loc[0,\"title_desc_lemma\"].count(\" \") + 1}\\n')\n",
    "df.loc[0,'title_desc_lemma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Graphique Nombre de Mots par Catégorie par Traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that a sentence with n words has n-1 spaces in it\n",
    "df['count_description'] = df['description']\\\n",
    "                            .apply(lambda row: row.count(' ') + 1)\n",
    "df['count_title'] = df['product_name']\\\n",
    "                            .apply(lambda row: row.count(' ') + 1)\n",
    "df['count_title_description'] = \\\n",
    "        df['title_desc'].apply(lambda row: row.count(' ') + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that a sentence with n words has n-1 spaces in it\n",
    "df['count_title_desc_clean'] = \\\n",
    "    df['title_desc_clean'].apply(lambda row: row.count(' ') + 1)\n",
    "df['count_title_desc_lemma'] = \\\n",
    "    df['title_desc_lemma'].apply(lambda row: row.count(' ') + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.groupby('category').mean()[['count_title_description',\n",
    "                                     'count_title_desc_clean',\n",
    "                                     'count_title_desc_lemma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "sns.lineplot(x=cat.index,\n",
    "             y=cat['count_title_description'],\n",
    "             linewidth=3,\n",
    "             marker='o',\n",
    "             markersize=20,\n",
    "             label='without processing')\n",
    "\n",
    "sns.lineplot(x=cat.index,\n",
    "             y=cat['count_title_desc_clean'],\n",
    "             linewidth=3,\n",
    "             marker='o',\n",
    "             markersize=20,\n",
    "             label='after cleaning ')\n",
    "\n",
    "sns.lineplot(x=cat.index,\n",
    "             y=cat['count_title_desc_lemma'],\n",
    "             linewidth=3,\n",
    "             marker='o',\n",
    "             markersize=20,\n",
    "             label='after cleaning and lemmatization')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Category',fontsize=16)\n",
    "plt.xticks(rotation=20,ha='right')\n",
    "plt.ylabel('Number of words',fontsize=16)\n",
    "plt.title('Number of words per category per preprocessing', fontsize=24)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 - round(cat.count_title_desc_lemma.mean()/\n",
    "      cat.count_title_description.mean()*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En moyenne, les étapes de **cleaning** et <br />\n",
    "de **lematisation** suppriment **49.61%** <br />\n",
    "de <u>mots inutiles à la description de nos produits</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 Création du dictionnaire dictTxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de maintenant nous allons <br />\n",
    "manipuler différents objets.\n",
    "\n",
    "Pour plus de simplicité, <br />\n",
    "j'utiliserai un **dictionnaire** <br />\n",
    "où <u>chaque clé fera référence <br />\n",
    "à l'objet utilisé</u>.\n",
    "\n",
    "J'utiliserai également un ensemble <br />\n",
    "de **fonctions** que j'ai écrit et dont <br />\n",
    "vous trouverez les **déclarations** en <br />\n",
    "<u>première partie</u> de ce document.\n",
    "\n",
    "Le plus souvent, <u>ces fonctions prennent <br />\n",
    "en argument un dictionnaire</u> et nous <br />\n",
    "retourne un dictionnaire enrichi <br />\n",
    "d'une nouvelle clé contenant l'objet <br />\n",
    "désiré (matrice tf-idf, t-sne, etc.).\n",
    "\n",
    "J'ai essayé de choisir des noms <br />\n",
    "de fonction explicites, n'hésitez pas<br />\n",
    "à lire leur docstring si besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxt = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ajoute au dictionnaire la key \"**category**\" <br />\n",
    "contenant la feature \"**category**\" du DataFrame **df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxt['category'] = df.category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5 Création des vecteurs pondérés avec TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant créer notre **bag of words**.<br />\n",
    "Il s'agit du sac de mots, <u>sans ordre</u>, contenant <br />\n",
    "<u>l'ensemble du vocabulaire</u> conservé et <br />\n",
    "qui décrit au mieux nos produits.\n",
    "\n",
    "Chaque produit de notre jeu de données est <br />\n",
    "caractérisé par son <u>vocabulaire</u> et par le <br />\n",
    "<u>nombre d'occurrences</u> de chacun de ses mots <br />\n",
    "de vocabulaire.\n",
    "\n",
    "Nous pourrions donc créer un **vecteur**, <br />\n",
    "où chaque élément de ce vecteur correspondrait <br />\n",
    "à un mot du **bac of words**, et où chaque valeur <br />\n",
    "de chaque élément du vecteur correspondrait <br />\n",
    "au nombre d'occurrences du mot dans <br />\n",
    "la description du produit.\n",
    "\n",
    "Cette approche est intéressante, on émet l'hypothèse <br />\n",
    "que des catégories de produits rassemblent certains mots<br />\n",
    "de vocabulaire spécifiques plutôt que d'autres.\n",
    "\n",
    "Cependant, certains mots peuvent être fréquents <br />\n",
    "et commun à plusieurs ou même à toutes les catégories.<br />\n",
    "Nous allons donc *relativiser* l'occurrence d'un mot <br />\n",
    "en fonction de sa présence dans l'ensemble <br />\n",
    "des descriptions des produits.\n",
    "\n",
    "Pour réaliser cela je vais utiliser **tf-idf** avec sklearn.\n",
    "\n",
    "<u>Qu'est-ce que **TF-IDF**</u> :<br />\n",
    "Term Frequency – Inverse Document Frequency <br />\n",
    "est une mesure qui permet, à partir d’un <br />\n",
    "ensemble de textes, de connaître l’importance <br />\n",
    "relative de chaque mot.\n",
    "\n",
    "Idéalement, un terme apparaît très fréquemment <br />\n",
    "dans quelques textes seulement. <br />\n",
    "Les mots qui apparaissent dans presque tous les <br />\n",
    "documents ou très rarement n’ont que peu d’importance.\n",
    "\n",
    "**TF-IDF** va nous permettre de créer une matrice de vecteurs,<br />\n",
    "où chaque élement du vecteur représente un mot <br />\n",
    "du **bag of word** et la valeur de chaque élément <br />\n",
    "du vecteur représente l'importance d'un mot <br />\n",
    "relativisé à l'ensemble des documents (ici, <br />\n",
    "à l'ensemble des descriptions des produits <br />\n",
    "du jeu de données.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Création de la matrice tf-idf</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxt['tfidf'] = TfidfVectorizer()\\\n",
    "                     .fit_transform(df['title_desc_lemma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.6 Réduction de dimension PCA / T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin nous permettre de <u>visualiser graphiquement</u> <br />\n",
    "les **regroupements** de nos produits en fonction <br />\n",
    "de leur description mais également d'**améliorer <br />\n",
    "les performances** de notre moteur de classification, <br />\n",
    "nous allons appliquer une **réduction de dimension** <br />\n",
    "à notre matrice **tf-idf**.\n",
    "\n",
    "L'objectif ici est de ramener nos vecteurs en **2 dimensions**.\n",
    "\n",
    "Nous allons utiliser pour cela l'algorithme **T-SNE**.\n",
    "\n",
    "Cependant le charge peut-être très <br />\n",
    "lourde en termps de calcul.<br />\n",
    "Pour éviter cette problématique,<br />\n",
    "nous allons <u>appliquer une première <br />\n",
    "réduction de dimension</u> en appliquant <br />\n",
    "une <u>Analyse en Composante Principale</u>.<br />\n",
    "Nous ferons le choix de conserver **99% <br />\n",
    "de la variance** afin de ne pas sacrifier <br />\n",
    "la qualité de nos données tout en <br />\n",
    "réduisant drastiquement le temps necessaire <br />\n",
    "à l'application de **T-SNE** pour la réduction <br />\n",
    "en 2 dimensions de nos vecteurs TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxt = reductionTwoDimensionPCAandTSNE(dictTxt, col='tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Nous pouvons afficher notre matrice TF-IDF<br />\n",
    "maintenant réduite en 2 dimensions où <br />\n",
    "chaque point représente un produit</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(dictTxt['tsne'][:,0], dictTxt['tsne'][:,1])\n",
    "plt.title('TF-IDF matrix in 2 dimensions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut d'ores et déjà remarquer <br />\n",
    "des **regroupements** parmi les produits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.7 Affichage de la classification des descriptions selon leurs catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutons maintenant un peu de couleur.<br />\n",
    "Chaque produit est maintenant représenté <br />\n",
    "par une <u>couleur représentant sa catégorie</u><br />\n",
    "parmi les 7 existantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTSNESortedByColor(dictTxt,hue='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines catégories semblent très bien regroupées <br />\n",
    "comme \"**Watches**\" ou \"**Beauty and Personal Care**\".<br />\n",
    "D'autres sont plus diffuses comme \"**Home Furnising**\".\n",
    "\n",
    "On peut émettre l'hypothèse que <u>les groupes <br />\n",
    "correctement taggés ont un vocubulaire très <br />\n",
    "spécifique</u> alors que <u>les autres ont un vocubulaire <br />\n",
    "plus général</u> susceptible d'être présent dans <br />\n",
    "plusieurs catégories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.8 K-Means sur matrice T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée à présent et de faire comme si <br />\n",
    "nous ne connaissions pas la réelle <br />\n",
    "catégorie des produits.\n",
    "\n",
    "A partir de la matrice **T-SNE**, nous allons regrouper, <br />\n",
    "via l'algorithme **K-Means** les points selon **7 clusters**.<br />\n",
    "Chaque cluster représente l'une des 7 catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxt = createKMeansLabelsFromTSNE(dictTxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.9 Affichage de la classification des descriptions selon leurs clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Affichons maintenant les produits selon leurs clusters K-Means</u> : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTSNESortedByColor(dictTxt,hue='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici les clusters sont beaucoup plus <br />\n",
    "nets et bien délimités que précédement.\n",
    "\n",
    "On constate que certains clusters <br />\n",
    "représentent assez fidèlement certaines <br />\n",
    "vraies catégories, encore une fois <br />\n",
    "comme \"**Watches**\" ou \"**Beauty and Personal Care**\".\n",
    "\n",
    "Cependant les catégories les plus diffuses<br />\n",
    "ont bien entendu des produits mal <br />\n",
    "classés par **K-Means**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.10 Matrice de Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisons la **matrice de confusion** <br />\n",
    "pour <u>visualiser les erreurs de classement</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showConfusionMatrix(dictTxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les catégories ont la majorité de leurs produits<br />\n",
    "qui sont correctements classés.<br />\n",
    "Les clusters peuvent être attribués à leur catégorie <br />\n",
    "respective en identifiant, pour chaque catégorie, <br />\n",
    "le cluster qui la représente le plus.<br />\n",
    "La catégorie \"**Computers**\" est la catégorie <br />\n",
    "la plus difficile à classer. Presque la moitié des produits <br />\n",
    "est attribuée à tort à la catégorie \"**Beauty and Personal Care**.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.11 Calcul du Score ARI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mesurer l'erreur de notre moteur <br />\n",
    "de classification, nous allons utiliser <br />\n",
    "la métrique **ARI** via la fonction <br />\n",
    "**adjusted_rand_score** de sklearn.\n",
    "\n",
    "L'**adjusted_rand_score** calcule une mesure <br />\n",
    "de similarité entre deux groupements <br />\n",
    "en considérant toutes les paires d'échantillons <br />\n",
    "et en comptant les paires qui sont assignées <br />\n",
    "dans le même groupement ou dans des groupements <br />\n",
    "différents dans les groupements prédits et réels.\n",
    "\n",
    "*Le score ARI va de 0 pour un étiquetage aléatoire <br />\n",
    "à 1 pour un étiquetage parfait*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewARIScore(dictTxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selon les essais nous obtenons <br />\n",
    "un score variant de **0.44** à **0.56**.<br />\n",
    "C'est un score très encourageant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Classification des produits grâce à leurs images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant tenter de classer \n",
    "nos produits selon l'image associée à leur description.\n",
    "\n",
    "Ici l'idée est similaire à l'analyse de texte :\n",
    " 1. Obtenir des features des images,<br />\n",
    "    à partir de leurs descripteurs\n",
    " 2. Créer un **Bag of *Virtual* Words** <br />\n",
    "    à partir de l'ensemble des features existantes\n",
    " 3. Créer des <u>vecteurs de caractéristiques</u><br />\n",
    "    à partir du **Bag of *Virtual* Words**\n",
    " 4. Réaliser une <u>réduction de dimension</u> sur nos vecteurs\n",
    " 5. <u>Clusteriser</u> notre matrice de vecteurs\n",
    " 6. <u>Evaluer</u> le résultat de la clusterisation <br />\n",
    "    de notre moteur de classification avec <br />\n",
    "    la catégorie réelle associée à chaque image\n",
    "\n",
    "<u>Je détaille ci-dessous \n",
    "deux approches</u> :\n",
    " - **SIFT** pour Scale-Invariant Feature Transform\n",
    " - **VGG16** qui est un modèle de réseau de neurones convolutifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Méthode SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La scale-invariant feature transform (**SIFT**), <br />\n",
    "que l'on peut traduire par « transformation <br />\n",
    "de caractéristiques visuelles invariante à l'échelle », <br />\n",
    "est un <u>algorithme utilisé pour détecter et identifier <br />\n",
    "les éléments similaires entre différentes images <br />\n",
    "numériques</u> (éléments de paysages, objets, personnes, etc.). <br />\n",
    "Il a été développé en 1999.\n",
    "\n",
    "L'étape fondamentale de la méthode consiste <br />\n",
    "à calculer ce que l'on appelle les « **descripteurs <br />\n",
    "SIFT** » des images à étudier. <br />\n",
    "Il s'agit d'informations numériques dérivées <br />\n",
    "de l'analyse locale d'une image et qui caractérisent <br />\n",
    "le contenu visuel de cette image de la façon <br />\n",
    "la plus <u>indépendante possible de l'échelle</u> (« zoom » <br />\n",
    "et résolution du capteur), <u>du cadrage, de l'angle <br />\n",
    "d'observation et de l'exposition</u> (luminosité). \n",
    "\n",
    "Ainsi, **deux photographies d'un même objet** auront <br />\n",
    "toutes les chances d'avoir des **descripteurs SIFT <br />\n",
    "similaires**, et ceci d'autant plus si les instants <br />\n",
    "de prise de vue et les angles de vue sont proches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Voici le protocole que l'on va mettre en place,<br />\n",
    "pour créer notre moteur de classification des <br />\n",
    "produits à partir des images avec **SIFT**</u> :\n",
    "\n",
    "1. Pour chaque image du jeu de données\n",
    "  - Lire l'image\n",
    "  - Réaliser le **pre-processing** de l'image <br />\n",
    "    *pour augmenter la capacité de SIFT à <br />\n",
    "    détecter correctement les descripteurs*\n",
    "   - Passer l'image en **niveau de gris** (par <br />\n",
    "     souci de simplicité, les couleurs ne <br />\n",
    "     changent pas fondamentalement le score final)\n",
    "   - Application d'un **flou gaussien**\n",
    "   - Egalisation de l'histogramme\n",
    "   - **Extraction** des descripteurs\n",
    "2. Création d'une matrice contenant <br />\n",
    "   **l'ensemble des descripteurs**\n",
    "3. **Clustérisation** pour création <br />\n",
    "   des **Bag of *Virtual* Words**\n",
    "4. Création des **Histogrammes**\n",
    "5. Réduction de dimension **PCA** + **T-SNE**\n",
    "6. Calcul du score **ARI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Création du dictionnaire dictImages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la même manière que la partie texte, <br />\n",
    "j'utilise un **dictionnaire** pour stocker <br />\n",
    "et manipuler nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictImages = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 Ajout du path des images..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'importe le chemin complet (dossier + nom de fichier) <br />\n",
    "de chaque image sous forme de **Series Pandas** pour <br />\n",
    "qu'elles puissent êtres accessibles facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictImages['path'] = data['image'].apply(lambda row: 'Flipkart/Images/'+row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 ...et de leurs catégories respectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'importe également sous forme de **Series Pandas** <br />\n",
    "les catégories associées à chaque image.<br />\n",
    "Comme les index sont les mêmes, l'ordre <br />\n",
    "image/categorie est respecté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictImages['category'] = df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.4 Calcul et regroupement de l'ensemble des descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On parcourt chacune des images referencées <br />\n",
    "dans notre dictionnaire **dictImages** (chaque <br />\n",
    "élement de la key \"path\") <br />\n",
    "\n",
    "<u>Puis pour chaque image</u> :\n",
    " 1. On charge l'image pour pouvoir travailler avec\n",
    " 2. <u>On applique les pre-processing suivants</u> :\n",
    "  1. Passage en niveau de gris\n",
    "  2. Flou Gaussien\n",
    "  3. Egalisation de l'Histogramme\n",
    " 3. On applique SIFT à l'image pré-processée <br />\n",
    "    pour extraire les descripteurs de l'image\n",
    " 4. On ajoute les descripteurs à une matrice<br /> \n",
    "    destinée à contenir tous les descripteurs <br />\n",
    "    de toutes les images\n",
    " 5. On ajoute la matrice des descripteurs <br />\n",
    "    à la key \"**totalDes**\" de notre dictionnaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictImages = groupAllDescriptors(dictImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictImages['totalDes'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient une matrice de **4 185 939 descripteurs**.<br />\n",
    "Chaque descripteur est un vecteur de dimension (**1**,**128**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.5 A propos du pre-processing des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'affiche ci-dessous <u>1 image du jeu de données <br />\n",
    "et son histogramme associé</u>, en appliquant <br />\n",
    "successivement les opérations de pré-processing suivant:\n",
    " 1. Aucun pré-processing\n",
    " 2. Passage en niveau de gris\n",
    " 3. Passage en niveau de gris + Flou Gaussien\n",
    "  - Le Flou Gaussien nous sert à nettoyer l'image de son bruit.<br />\n",
    "    Il évite à SIFT de détecter de mauvais descripteurs.<br />\n",
    " 4. Passage en niveau de gris + Flou Gaussien + Egalisation de l'histogramme\n",
    "  - L'égalisation de l'histogramme accentue <br />\n",
    "    le contraste de l'image et améliore les performances <br />\n",
    "    de SIFT dans la détection des descripteurs.\n",
    "\n",
    "<u>Attention, dans cette partie j'évoque le terme <br />\n",
    "***histogramme*** dans deux contextes différents</u> :\n",
    "\n",
    " - L'histogramme affiché ci-dessous correspond <br />\n",
    "   à l'histogramme *classique* que l'on retrouve <br />\n",
    "   par exemple dans les logiciels d'édition de photographie.\n",
    "    - En photographie, l’histogramme nous permet de visualiser <br />\n",
    "      comment se distribuent les tons clairs et foncés <br />\n",
    "      dans notre image.<br />\n",
    "      Autrement dit, il donne des informations sur <br />\n",
    "      l’exposition de notre image.\n",
    "      \n",
    "      Plus simplement, à gauche de l’histogramme <br />\n",
    "      sont représentés les pixels sombres, et à droite <br />\n",
    "      les pixels clairs. <br />\n",
    "      Plus il y a de pixels pour une tonalité <br />\n",
    "      (très sombre, moyen, très clair, et tous les <br />\n",
    "      intermédiaires), plus son “pic” sera élevé.\n",
    " - L'histogramme s'appuyant sur les **bac of *virtual* words** <br />\n",
    "   (J'évoque ces histogrammes un peu plus bas dans cette partie.)<br />\n",
    "   reprend le même principe que les histogrammes classiques.<br />\n",
    "   Là où l'histogramme classique représente de gauche à droite <br />\n",
    "   les tons clairs, moyens et foncés d'une image, <br />\n",
    "   l'histogramme utilisé dans le contexte des **bag <br />\n",
    "   of *virtual* words** représente quand à lui,<br />\n",
    "   sur l'axe horizontal, l'ensemble des virtual words existants, <br />\n",
    "   et sur l'axe vertical le nombre d'occurences des virtual words <br />\n",
    "   au sein de l'image.<br />\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "displayTheFourImagesAndTheirHistograms(dictImages,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.6 Création du Bag of Virtual Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous cherchons à trouver l'équivalent des mots,<br />\n",
    "en tant que **features**, que nous avions pour <br />\n",
    "l'analyse du texte.<br />\n",
    "Pour retrouver l'équivalent des mots,<br /> \n",
    "nous allons créer des **mots virtuels**.\n",
    "\n",
    "Grâce à l'algorithme **MiniBatchKMeans** <br />\n",
    "(une variante de l'algorithme KMeans <br />\n",
    "optimisé pour réduire le temps de calcul),<br />\n",
    "nous allons clusteriser notre matrice <br />\n",
    "de descripteurs calculée précedement.\n",
    "\n",
    "Les descripteurs dont les caractéristiques <br />\n",
    "seront proches seront naturellement regroupés <br />\n",
    "dans des clusters identiques.\n",
    "\n",
    "<u>Chaque centroïde sera alors considéré <br />\n",
    "comme un mot virtuel</u>.\n",
    "\n",
    "<u>La fonction **createKmeansOfBagOfVirtualWords** <br />\n",
    "définie les **deux hyperparamètres** de <br />\n",
    "**MiniBatchKMeans** de la manière suivante</u> : \n",
    "\n",
    "- <u>nClusters</u>: Le nombre de clusters\n",
    "  - Est défini comme l'entier le plus proche <br />\n",
    "    de la racine carrée du nombre total de descripteurs.\n",
    "- <u>batchSize</u> : La taille des mini-lots<br />\n",
    "  - Est défini comme 3 fois le nombre d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictImages = createKmeansOfBagOfVirtualWords(dictImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictImages['kmeans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un **MiniBatchKMeans** entrainé avec **2046 clusters**.<br />\n",
    "Chaque centroïde de ces clusters représente les *mots* <br />\n",
    "de notre **Bag of Virtual Words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.7 Création des histogrammes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant créer les **histogrammes** <br />\n",
    "de nos images.<br />\n",
    "<u>Un histogramme est un vecteur de caractéristiques</u>.\n",
    "\n",
    "Nous allons réaliser pour nos images le même genre <br />\n",
    "d'opération qu'avec **TF-IDF** pour le texte de la <br />\n",
    "partie précedente.\n",
    "\n",
    "Un histogramme est un vecteur où chaque élement <br />\n",
    "du vecteur correspond à un mot virtuel.<br />\n",
    "La dimension de notre matrice d'histogrammes est <br />\n",
    "donc égale à (Nombre d'images, Nombre de Clusters)<br />\n",
    "soit ici (**1050**,**2046**).\n",
    "\n",
    "<u>Pour renseigner chaque élement du vecteur d'une image <br />\n",
    "nous réalisons les opérations suivantes</u> :\n",
    "\n",
    " - **Création d'un vecteur rempli de 0** <br />\n",
    "   de dimension (1,Nombre_de_Clusters)\n",
    " - **Calcul des descripteurs des images** <br />\n",
    "   selon le même procédé que vu précedement\n",
    " - Pour chaque descripteur:\n",
    "  - Calcul d'un **predict** sur le **MiniBatrchKMeans** entrainé\n",
    "  - Le label obtenu correspond au mot <br />\n",
    "    *virtuel* associé à ce descripteur\n",
    "   - Le Label correspond à l'indice <br />\n",
    "     du vecteur histogramme\n",
    "   - Par exemple si le label calculé pour <br />\n",
    "     le 1er descripteur de la première image <br />\n",
    "     est 3, alors nous renseignerons l'indice 3 <br />\n",
    "     du vecteur de 0 crée précedement\n",
    "  - On incrémente le vecteur de 0 associé <br />\n",
    "    à l'image du descripteur calculé\n",
    "   - Les histogrammes que nous créons sont **normalisés**.<br />\n",
    "     Par conséquent, on incrémente l'histogramme <br />\n",
    "     à l'indice correspondant de *1/Nombre_De_Descripteurs_Total*\n",
    "  \n",
    "Une fois l'opération réalisée pour <br />\n",
    "tous les descripteurs d'une image, <br />\n",
    "l'histogramme est finalisé.\n",
    "\n",
    "Nous réalisons cette opération <br />\n",
    "pour toutes les images.\n",
    "\n",
    "Nous obtenons une matrice de <br />\n",
    "dimension (**Nombre d'images**, **Nombre de mots virtuels** <br />\n",
    "(c'est à dire de centroïdes dans le MiniBatchKMeans <br />\n",
    "entrainé) ce qui correspond dans notre cas à (**1050**,**2046**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictImages = createHistograms(dictImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.8 Réduction de dimension PCA / T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin nous permettre de <u>visualiser graphiquement</u> <br />\n",
    "les **regroupements** de nos produits en fonction <br />\n",
    "de leur description mais également d'**améliorer <br />\n",
    "les performances** de notre moteur de classification, <br />\n",
    "nous allons appliquer une réduction de dimension <br />\n",
    "à notre matrice de vecteurs.\n",
    "\n",
    "L'objectif ici est de ramener nos vecteurs en **2 dimensions**.\n",
    "\n",
    "Nous allons utiliser pour cela l'algorithme **T-SNE**.\n",
    "\n",
    "Cependant la charge peut-être très <br />\n",
    "lourde en temps de calcul.<br />\n",
    "Pour éviter cette problématique,<br />\n",
    "nous allons <u>appliquer une première <br />\n",
    "réduction de dimension</u> en appliquant <br />\n",
    "une <u>Analyse en Composante Principale</u>.<br />\n",
    "Nous ferons le choix de conserver **99% <br />\n",
    "de la variance** afin de ne pas sacrifier <br />\n",
    "la qualité de nos données tout en <br />\n",
    "réduisant drastiquement le temps nécessaire <br />\n",
    "à l'application de **T-SNE** pour la réduction <br />\n",
    "en 2 dimensions de nos histogrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictImages = reductionTwoDimensionPCAandTSNE(dictImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Nous pouvons afficher notre matrice d'histogrammes<br />\n",
    "maintenant réduite en 2 dimensions où <br />\n",
    "chaque point représente un produit</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(dictImages['tsne'][:,0], dictImages['tsne'][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ce stade, aucun regroupement de points ne semble se démarquer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.9 Affichage de la classification des images selon leurs catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutons maintenant un peu de couleur.<br />\n",
    "Chaque produit est maintenant représenté <br />\n",
    "par une couleur représentant sa catégorie<br />\n",
    "parmi les 7 existantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTSNESortedByColor(dictImages,hue='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est très difficile de distinguer <br />\n",
    "des regroupements selon les catégories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.10 K-Means sur matrice T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée à présent et de faire comme si <br />\n",
    "nous ne connaissions pas la réelle <br />\n",
    "catégorie des produits.\n",
    "\n",
    "A partir de la matrice **T-SNE**, nous allons regrouper, <br />\n",
    "via l'algorithme **K-Means** les points selon **7 clusters**.<br />\n",
    "Chaque cluster représente l'une des 7 catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createKMeansLabelsFromTSNE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d469bba721c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdictImages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateKMeansLabelsFromTSNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictImages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'createKMeansLabelsFromTSNE' is not defined"
     ]
    }
   ],
   "source": [
    "dictImages = createKMeansLabelsFromTSNE(dictImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.11 Affichage de la classification des images selon leurs clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Affichons maintenant les produits selon leurs clusters K-Means</u> : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "displayTSNESortedByColor(dictImages,hue='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les points sont ici regroupées d'une manière beaucoup plus homogène."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.13 Matrice de Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisons la **matrice de confusion** <br />\n",
    "pour <u>visualiser les erreurs de classement</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showConfusionMatrix(dictImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les catégories sont mal classées et il est impossible <br />\n",
    "d'associer avec certitude une catégorie à un numéro de cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.12 Calcul du Score ARI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mesurer l'erreur de notre moteur <br />\n",
    "de classification, nous allons utiliser <br />\n",
    "la métrique **ARI** via la fonction <br />\n",
    "**adjusted_rand_score** de sklearn.\n",
    "\n",
    "L'**adjusted_rand_score** calcule une mesure <br />\n",
    "de similarité entre deux groupements <br />\n",
    "en considérant toutes les paires d'échantillons <br />\n",
    "et en comptant les paires qui sont assignées <br />\n",
    "dans le même groupement ou dans des groupements <br />\n",
    "différents dans les groupements prédits et réels.\n",
    "\n",
    "*Le score ARI va de 0 pour un etiquetage aléatoire <br />\n",
    "à 1 pour un étiquetage parfait*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewARIScore(dictImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons un score d'environ **7.5%**<br />\n",
    "Celà peut parraitre peu mais les images <br />\n",
    "n'étaient vraiment pas optimisées ni en nombre suffisant.<br />\n",
    "<u>Ce score peut-être amélioré</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Méthode Transfert Learning avec VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans cette partie utiliser **Keras**,<br />\n",
    "une bibliothèque de **Deep Learning**.\n",
    "\n",
    "Nous utiliserons une version du <u>réseau de neurones <br />\n",
    "convolutif VGG-Net nommé **VGG16**</u>.\n",
    "\n",
    "Le modèle **VGG16** atteint une précision de **92,7%** <br />\n",
    "dans le top 5 des tests d'**ImageNet**.<br />\n",
    "**ImageNet** est un ensemble de données de plus <br />\n",
    "de <u>15 millions d'images haute résolution <br />\n",
    "étiquetées</u> appartenant à environ **22 000 catégories**. \n",
    "\n",
    "**Keras** nous fourni une version pré-entraînée de **VGG16**.\n",
    "\n",
    "Pour mettre en place notre moteur de classification <br />\n",
    "d'images, nous appliquerons une technique <br />\n",
    "nommée *Transfert Learning*.\n",
    "\n",
    "Simplement, le *Transfert Learning* consiste <br />\n",
    "à utiliser la connaissance déjà acquise <br />\n",
    "par un modèle entraîné (ici **VGG16**) pour l'adapter <br />\n",
    "à notre problématique.\n",
    "\n",
    "Actuellement **VGG16** permet de classer une image <br />\n",
    "parmi **1000 catégories** différentes.\n",
    "\n",
    "Nous souhaitons donc pouvoir <u>utiliser <br />\n",
    "la puissance de **VGG16**</u> mais <u>adaptée à <br />\n",
    "notre problématique</u>. C'est à dire pouvoir <br />\n",
    "<u>classer une image</u> non pas parmi 1000 catégories <br />\n",
    "mais <u>parmi nos 7 catégories</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 Installer Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'aller plus loin,<br />\n",
    "vous devrez installer Keras.\n",
    "\n",
    "<u>Pour installer Keras</u> : \n",
    " - Dans Anaconda Prompt\n",
    "  - \"conda install -c anaconda keras-gpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 Explication rapide de VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Voici une vue des différentes couches de VGG16</u> :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Représentation VGG16](https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG-16** est constitué de plusieurs couches, <br />\n",
    "dont **13** couches de convolution et **3** fully-connected. <br />\n",
    "\n",
    "<u>Il prend en entrée une image en couleurs de taille 224  × 224 px</u> <br />\n",
    "et la classifie dans une des 1000 classes. <br />\n",
    "<u>Il renvoie donc un vecteur de taille 1000</u>, <br />\n",
    "qui contient les probabilités d'appartenance <br />\n",
    "à chacune des classes. \n",
    "\n",
    "Dans notre approche *Transfert Learning*, nous n'allons <br />\n",
    "pas utiliser la dernière couche **softmax** chargée de <br />\n",
    "classer l'image parmi l'une des 1000 catégories.\n",
    "\n",
    "Nous récupérerons, pour chaque image, le **vecteur** <br />\n",
    "de dimension (**1**,**1**,**4096**), puis, comme pour la méthode SIFT,<br /> \n",
    "ou pour le traitement du texte que nous avons <br />\n",
    "réalisé précedement dans ce projet, nous répéterons <br />\n",
    "les étapes de :\n",
    " - Réduction de dimension \n",
    " - Clustering \n",
    " - Et enfin nous calculerons le score ARI <br />\n",
    "   entre le groupement des produits selon <br />\n",
    "   les catégories et les labels d'un <br />\n",
    "   clustering KMeans réalisé sur la <br />\n",
    "   projection en 2 dimensions de nos vecteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 Création du modèle pré-entrainé par Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans un premier temps <u>importer le modèle VGG16</u>.<br />\n",
    "Puis nous créerons ensuite <u>notre propre modèle</u>, <br />\n",
    "qui sera <u>une copie de VGG16 à l'exception de <br />\n",
    "la dernière couche **softmax**</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Création du modèle VGG-16 implémenté par Keras</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights=\"imagenet\",\n",
    "              include_top=True, # test avec True\n",
    "              input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>On indique qu'on ne souhaite ré-entrainer <br />\n",
    "aucune des couches du modèle</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>On définit le nouveau modèle en <br />\n",
    "définissant son entrée et sa sortie</u> :\n",
    "\n",
    "<u>En entrée</u>, nous voulons utiliser l'entrée du modèle VGG16<br />\n",
    "<u>En sortie</u>, nous souhaitons obtenir le vecteur généré <br />\n",
    "par VGG16 juste avant la dernière couche softmax, <br />\n",
    "soit son **avant-dernière couche**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(inputs=model.input, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Pour s'assurer que le nouveau modèle est <br />\n",
    "bien configuré, j'affiche son résumé que <br />\n",
    "je compare avec le modèle VGG16 initial</u> : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Résumé du modèle VGG16</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Résumé de notre nouveau modèle </u>:<br />\n",
    "On remarque que la dernière couche <br />\n",
    "n'a pas été importée et que le modèle <br />\n",
    "ne va pas être ré-entrainé, même partiellement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 Création du dictionnaire dictModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme précedement, j'utilise un dictionnaire <br />\n",
    "pour stocker et manipuler nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictModel={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.5 Ajout du path des images..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'importe le chemin complet (dossier + nom de fichier) <br />\n",
    "de chaque image sous forme de **Series Pandas** pour <br />\n",
    "qu'elles puissent être accessibles facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictModel['path'] = data.copy()['image'].apply(lambda row: 'Flipkart/Images/'+row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.6 ...et de leurs catégories respectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'importe également sous forme de **Series Pandas** <br />\n",
    "les catégories associées à chaque image.<br />\n",
    "Comme les index sont les mêmes, l'ordre <br />\n",
    "image/catégorie est respecté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictModel['category'] = df.copy()['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.7 Préparation des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>VGG16 attend en entrée une matrice d'images<br /> \n",
    "en 4 dimensions composée de la façon suivante</u> :\n",
    " - <u>1ère dimension</u> : Correspond au nombre d'images importées\n",
    "  - 1050 dans notre cas\n",
    " - <u>2ème et 3ème dimension</u> : correspond à la largeur et hauteur de l'image\n",
    "  - VGG16 attend en entrée des images de 224 x 224 px.\n",
    " - <u>4ème dimension</u> : Correspond à la profondeur de l'image\n",
    "  - Vaut 3 si les photos sont en couleurs (notre cas)\n",
    "  - Vaut 1 si les photos sont en noir et blanc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Préparons les images au bon format <br />\n",
    "pour notre Model basé sur VGG16</u> :\n",
    " 1. Je crée un matrice d'images en 4 dimensions<br />\n",
    " 2. Chaque image est préalablement redimensionnée <br />\n",
    "    avec les dimensions 224 x  224 px.\n",
    " 3. La matrice est stockée à l'intérieur du <br />\n",
    "    dictionnaire sous la clé \"**arrayImg**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictModel = createMatrixOfImages(dictModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.8 Extraction des histogrammes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir nos histogrammes avec notre <br />\n",
    "nouveau modèle, il suffit d'utiliser la méthode<br />\n",
    "**predict** en passant en argument la matrice <br />\n",
    "d'images en 4 dimensions.\n",
    "\n",
    "Le modèle nous retourne une matrice <br />\n",
    "de (ici 1050) vecteurs, où chaque vecteur <br />\n",
    "est de dimension (1, 4096)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictModel['histograms'] = new_model.predict(dictModel['arrayImg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictModel['histograms'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.9 Clustering PCA / T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin nous permettre de <u>visualiser graphiquement</u> <br />\n",
    "les **regroupements** de nos produits en fonction <br />\n",
    "de leur description mais également d'**améliorer <br />\n",
    "les performances** de notre moteur de classification, <br />\n",
    "nous allons appliquer une réduction de dimension <br />\n",
    "à notre matrice de vecteurs.\n",
    "\n",
    "L'objectif ici est de ramener nos vecteurs en **2 dimensions**.\n",
    "\n",
    "Nous allons utiliser pour cela l'algorithme **T-SNE**.\n",
    "\n",
    "Cependant la charge peut-être très <br />\n",
    "lourde en temps de calcul.<br />\n",
    "Pour éviter cette problématique,<br />\n",
    "nous allons <u>appliquer une première <br />\n",
    "réduction de dimension</u> en appliquant <br />\n",
    "une <u>Analyse en Composante Principale</u>.<br />\n",
    "Nous ferons le choix de conserver **99% <br />\n",
    "de la variance** afin de ne pas sacrifier <br />\n",
    "la qualité de nos données tout en <br />\n",
    "réduisant drastiquement le temps nécessaire <br />\n",
    "à l'application de **T-SNE** pour la réduction <br />\n",
    "en 2 dimensions de nos histogrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictModel = reductionTwoDimensionPCAandTSNE(dictModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Nous pouvons afficher notre matrice d'histogrammes<br />\n",
    "maintenant réduite en 2 dimensions où <br />\n",
    "chaque point représente un produit</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(dictModel['tsne'][:,0], dictModel['tsne'][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les produits semblent nettement plus répartis <br />\n",
    "par groupe que lors de l'utilisation de SIFT.<br />\n",
    "Même si à ce stade il n'est pas possible de <br />\n",
    "savoir à quel point le moteur de classification <br />\n",
    "sera efficace, cette première représentation <br />\n",
    "avec notre model basé sur VGG16 semble plus <br />\n",
    "efficace que la méthode SIFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.10 Affichage de la classification des images selon leurs catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutons maintenant un peu de couleur.<br />\n",
    "Chaque produit est maintenant représenté <br />\n",
    "par une couleur représentant sa catégorie<br />\n",
    "parmi les 7 existantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "displayTSNESortedByColor(dictModel,hue='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour le classement à partir de la description <br />\n",
    "texte des images, certaines catégories semblent <br />\n",
    "très bien regroupées comme \"**Watches**\" ou \"**Beauty and Personal Care**\".<br />\n",
    "D'autres sont plus diffuses comme \"**Home Furnising**\".\n",
    "\n",
    "On peut émettre l'hypothèse que les groupes <br />\n",
    "correctement taggués ont des caractéristiques visuelles très <br />\n",
    "spécifiques alors que les autres ont des caractéristiques <br />\n",
    "plus générales et susceptibles d'être présentes dans <br />\n",
    "plusieurs catégories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.11 K-Means sur matrice T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée à présent et de faire comme si <br />\n",
    "nous ne connaissions pas la réelle <br />\n",
    "catégorie des produits.\n",
    "\n",
    "A partir de la matrice **T-SNE**, nous allons regrouper, <br />\n",
    "via l'algorithme **K-Means** les points selon **7 clusters**.<br />\n",
    "Chaque cluster représente l'une des 7 catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictModel = createKMeansLabelsFromTSNE(dictModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.12 Affichage de la classification des images selon leurs clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Affichons maintenant les produits selon leurs clusters K-Means</u> : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTSNESortedByColor(dictModel,hue='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici les clusters sont beaucoup plus <br />\n",
    "nets et bien délimités que précedement.\n",
    "\n",
    "On constate que certains clusters <br />\n",
    "représentent assez fidèlement certaines <br />\n",
    "vraies catégories, encore une fois <br />\n",
    "comme \"**Watches**\" ou \"**Beauty and Personal Care**\".\n",
    "\n",
    "Cependant les catégories les plus diffuses<br />\n",
    "ont bien entendu des produits mal <br />\n",
    "classés par **K-Means**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.13 Matrice de Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisons la **matrice de confusion** <br />\n",
    "pour <u>visualiser les erreurs de classement</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showConfusionMatrix(dictImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines catégories ont leurs produits<br />\n",
    "qui sont correctements classés.<br />\n",
    "D'autres catégories n'ont pas pu être associées <br />\n",
    "clairement à un cluster comme la catégorie \"**Baby Care**\".\n",
    "\n",
    "Il est impossible d'associer avec certitude <br />\n",
    "une catégorie à un numéro de cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.14 Calcul du Score ARI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mesurer l'erreur de notre moteur <br />\n",
    "de classification, nous allons utiliser <br />\n",
    "la métrique **ARI** via la fonction <br />\n",
    "**adjusted_rand_score** de sklearn.\n",
    "\n",
    "L'**adjusted_rand_score** calcule une mesure <br />\n",
    "de similarité entre deux groupements <br />\n",
    "en considérant toutes les paires d'échantillons <br />\n",
    "et en comptant les paires qui sont assignées <br />\n",
    "dans le même groupement ou dans des groupements <br />\n",
    "différents dans les groupements prédits et réels.\n",
    "\n",
    "*Le score ARI va de 0 pour un étiquetage aléatoire <br />\n",
    "à 1 pour un étiquetage parfait*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewARIScore(dictModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selon les essais nous obtenons <br />\n",
    "un score variant de **0.45** à **0.50**.<br />\n",
    "C'est un score très encourageant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Fusion des features Textes et Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons testé notre moteur de classification à partir <br />\n",
    "des **textes de description** des produits puis de leurs **images**, <br />\n",
    "nous allons tenter d'**améliorer l'efficacité de notre<br />\n",
    "moteur de classification** en <u>fusionnant les vecteurs <br />\n",
    "de caractéristiques</u> obtenus avec **TF-IDF** pour l'analyse textuelle,<br />\n",
    "puis <u>les vecteurs issus de notre modèle basé sur **VGG16**</u><br />\n",
    "pour l'analyse des images.\n",
    "\n",
    "Nous obtiendrons ainsi, pour chaque produit, <u>un unique vecteur <br />\n",
    "de caractéristiques</u> provenant à la fois des **features <br />\n",
    "textes et images**.\n",
    "\n",
    "Les étapes de réalisation seront exactement <br />\n",
    "les mêmes que vu précedement.<br />\n",
    "Je ne rentrerai donc pas dans les détails dans cette partie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Création et initialisation du dictionnaire dictTxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Je crée un nouveau dictionnaire dans lequel j'importe</u> :\n",
    " - Les vecteurs de caractéristiques textuelles\n",
    " - Les vecteurs de caractéristiques des images <br />\n",
    "   obtenus à partir du modèle basé sur VGG16\n",
    " - La liste des catégories associées à chaque produit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxtImages = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxtImages['category'] = dictTxt['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxtImages['tfidf'] = dictTxt['tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxtImages['histograms'] = dictModel['histograms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Fusion des vecteurs de caractéristiques de textes et d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je combine les deux matrices de vecteurs en une seule <br />\n",
    "et je stocke cette nouvelle matrice dans <br />\n",
    "la clé \"**vectors**\" du dictionnaire **dictTxtImages**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxtImages = combineTwoMatricesInOne(dictTxtImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Clustering PCA / T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>On effectue la réduction des vecteurs en 2 dimensions</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxtImages = reductionTwoDimensionPCAandTSNE(dictTxtImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Nous pouvons afficher notre matrice d'histogrammes<br />\n",
    "maintenant réduite en 2 dimensions où <br />\n",
    "chaque point représente un produit</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(dictTxtImages['tsne'][:,0], dictTxtImages['tsne'][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Affichage de la classification des produits selon leurs catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutons maintenant un peu de couleur.<br />\n",
    "Chaque produit est maintenant représenté <br />\n",
    "par une couleur représentant sa catégorie<br />\n",
    "parmi les 7 existantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTSNESortedByColor(dictTxtImages,hue='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour le classement à partir de la description <br />\n",
    "texte des images, certaines catégories semblent <br />\n",
    "très bien regroupées comme \"**Watches**\" ou \"**Beauty and Personal Care**\".<br />\n",
    "D'autres sont plus diffuses comme \"**Home Furnising**\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 K-Means sur matrice T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est toujours de faire comme si <br />\n",
    "nous ne connaissions pas la réelle <br />\n",
    "catégorie des produits.\n",
    "\n",
    "A partir de la matrice **T-SNE**, nous allons regrouper, <br />\n",
    "via l'algorithme **K-Means** les points selon **7 clusters**.<br />\n",
    "Chaque cluster représente l'une des 7 catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTxtImages = createKMeansLabelsFromTSNE(dictTxtImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Graphique Description/Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Affichons maintenant les produits selon leurs clusters K-Means</u> : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTSNESortedByColor(dictTxtImages,hue='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 Matrice de Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisons la **matrice de confusion** <br />\n",
    "pour <u>visualiser les erreurs de classement</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showConfusionMatrix(dictImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines catégories ont leurs produits<br />\n",
    "qui sont correctements classés.<br />\n",
    "D'autres catégories n'ont pas pu être associées<br />\n",
    "clairement à un cluster comme la catégorie \"**Baby Care**<br />\n",
    "ou la catégorie \"**Kitchen & Dining**\".\n",
    "\n",
    "Il est impossible d'associer avec certitude<br />\n",
    "une catégorie à un numéro de cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8 Calcul du Score ARI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mesurer l'erreur de notre moteur <br />\n",
    "de classification, nous allons utiliser <br />\n",
    "la métrique **ARI** via la fonction <br />\n",
    "**adjusted_rand_score** de sklearn.\n",
    "\n",
    "L'**adjusted_rand_score** calcule une mesure <br />\n",
    "de similarité entre deux groupements <br />\n",
    "en considérant toutes les paires d'échantillons <br />\n",
    "et en comptant les paires qui sont assignées <br />\n",
    "dans le même groupement ou dans des groupements <br />\n",
    "différents dans les groupements prédits et réels.\n",
    "\n",
    "*Le score ARI va de 0 pour un étiquetage aléatoire <br />\n",
    "à 1 pour un étiquetage parfait*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewARIScore(dictTxtImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons un score de même ordre de grandeur <br />\n",
    "qu'avec utilisation seul du moteur de classification <br />\n",
    "textuel ou par image avec le model basé sur VGG16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons successivement tenté de classer<br />\n",
    "nos produits à partir de leurs données<br />\n",
    "descriptives **textuelles** ainsi qu'à partir<br />\n",
    "de leurs **images**.<br />\n",
    "Nous avons ensuite tenté de classer les <br />\n",
    "produits en <u>**fusionnant** les données textes <br />\n",
    "et images</u>.\n",
    "\n",
    "Les tests ont été réalisés à partir d'un <br />\n",
    "petit échantillon de **1050** produits.\n",
    "\n",
    "A ce stade la classification à partir <br />\n",
    "des données textes (titre + description) <br />\n",
    "donne les résultats les plus satisfaisants.<br />\n",
    "L'analyse d'images n'apporte pas de précision <br />\n",
    "supplémentaire.\n",
    "\n",
    "Cependant, <u>la précision du moteur de classification<br /> \n",
    "basée sur l'analyse des images peut être grandement <br />\n",
    "améliorée</u> si nous décidons, par exemple, de ré-entrainer <br />\n",
    "un modèle basé sur **VGG16** à partir d'une base <br /> \n",
    "d'images correspondant à nos catégories de produits.\n",
    "\n",
    "Globalement, les résultats sont très **encourageants** <br />\n",
    "et nous permettent de donner <u>un avis **positif** <br />\n",
    "sur la faisabilité du moteur de classification</u>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
